# ğŸ§  Emotion Recognition System

<div align="center">

**Ultra-modern emotion recognition using EEG, PPG, and facial analysis**

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/)
[![PyQt6](https://img.shields.io/badge/PyQt6-6.6%2B-green.svg)](https://www.riverbankcomputing.com/software/pyqt/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

</div>

## âœ¨ Features

### ğŸ¨ Modern User Interface
- **Material Design** - Beautiful, professional UI with smooth animations
- **Dark/Light Themes** - Easy on the eyes with customizable themes
- **Responsive Layout** - Adapts to different screen sizes
- **Rich Icons** - Font Awesome icons throughout the interface
- **Real-time Visualizations** - Live EEG and camera feeds

### ğŸ§ª Multi-Modal Emotion Recognition
- **EEG Analysis** - Electroencephalogram signal processing using DEAP dataset
- **Facial Recognition** - Real-time face detection using MTCNN
- **PPG Support** - Photoplethysmogram analysis (coming soon)

### ğŸ¤– Machine Learning
- **Multiple Algorithms** - KNN, SVM, PCA+KNN, PCA+SVM
- **Binary Classification** - Arousal and valence prediction
- **Model Persistence** - Save and load trained models
- **Performance Metrics** - Accuracy scores and confusion matrices

### ğŸ—ï¸ Professional Architecture
- **Clean Code** - SOLID principles and separation of concerns
- **Type Hints** - Full type annotations for better IDE support
- **Error Handling** - Comprehensive exception handling and logging
- **Configuration Management** - Environment-based settings with Pydantic
- **Performance Optimized** - Fixed memory leaks and optimized rendering

## ğŸ“‹ Requirements

- Python 3.10 or higher
- DEAP Dataset (for EEG analysis)
- Webcam (for facial recognition)

## ğŸš€ Installation

### Using Hatch (Recommended)

```bash
# Clone the repository
git clone https://github.com/umitkacar/Emotion-Recognition-PyQt5.git
cd Emotion-Recognition-PyQt5

# Create virtual environment and install dependencies
hatch env create

# Run the application
hatch run emotion-recognition
```

### Using pip

```bash
# Clone the repository
git clone https://github.com/umitkacar/Emotion-Recognition-PyQt5.git
cd Emotion-Recognition-PyQt5

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install the package
pip install -e .

# Run the application
emotion-recognition
```

### Development Installation

```bash
# Install with development dependencies
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests
hatch run test

# Run linters
hatch run lint:all
```

## âš™ï¸ Configuration

Create a `.env` file in the project root (copy from `.env.example`):

```bash
# Application Settings
APP_NAME="Emotion Recognition System"
DEBUG=false
LOG_LEVEL=INFO

# Data Paths
DATA_DIR=./data
RAW_DATA_EEG_PATH=./data/deap/data_preprocessed_python
MODELS_DIR=./models
LOGS_DIR=./logs

# EEG Configuration
LABEL_THRESHOLD=4.5
N_USER_TOTAL=32
N_TRIAL_TOTAL=40

# Training Configuration
N_USER_TRAIN_START=1
N_USER_TRAIN_END=24
N_USER_TEST_START=25
N_USER_TEST_END=32

# Camera Settings
CAMERA_INDEX=0
CAMERA_WIDTH=640
CAMERA_HEIGHT=480
CAMERA_FPS=30

# UI Settings
WINDOW_WIDTH=1920
WINDOW_HEIGHT=1080
THEME=dark
LANGUAGE=Turkish
ANIMATION_DURATION=300

# Performance Settings
PLOT_UPDATE_INTERVAL=100
CAMERA_UPDATE_INTERVAL=33

# Machine Learning
DEFAULT_ML_MODEL=KNN
KNN_NEIGHBORS=5
KNN_LEAF_SIZE=200
```

## ğŸ“Š DEAP Dataset Setup

1. Download the DEAP dataset from [https://www.eecs.qmul.ac.uk/mmv/datasets/deap/](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/)
2. Extract the preprocessed Python data to `data/deap/data_preprocessed_python/`
3. The directory should contain files like `s01.dat`, `s02.dat`, etc.

## ğŸ¯ Usage

### Running the Application

```bash
# Using the installed command
emotion-recognition

# Or using Python module
python -m emotion_recognition.main
```

### EEG Analysis

1. Go to the **EEG** tab
2. Click **Start Visualization** to view real-time EEG signals
3. Observe:
   - Time domain signals (5 channels)
   - FFT spectrum analysis
   - Arousal-Valence plot

### Facial Recognition

1. Go to the **Camera** tab
2. Click **Open Camera** to start the webcam
3. Enable **Face Detection** checkbox to detect faces
4. Green bounding boxes will appear around detected faces

### Machine Learning

1. Go to the **ML Models** tab
2. Select a model (KNN, SVM, PCA+KNN, or PCA+SVM)
3. Click **Process Raw Data** to prepare the dataset
4. Click **Train Model** to train the selected algorithm
5. Click **Test Model** to evaluate on test data
6. Click **Show Results** to view accuracy and confusion matrices

## ğŸ›ï¸ Project Structure

```
Emotion-Recognition-PyQt5/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ emotion_recognition/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py              # Application entry point
â”‚       â”œâ”€â”€ config.py            # Configuration management
â”‚       â”œâ”€â”€ core/                # Business logic
â”‚       â”‚   â”œâ”€â”€ camera.py        # Camera management
â”‚       â”‚   â”œâ”€â”€ eeg_processor.py # EEG data processing
â”‚       â”‚   â””â”€â”€ ml_models.py     # Machine learning models
â”‚       â”œâ”€â”€ models/              # Data models
â”‚       â”‚   â”œâ”€â”€ eeg.py           # EEG data models
â”‚       â”‚   â””â”€â”€ face.py          # Face detection models
â”‚       â”œâ”€â”€ ui/                  # User interface
â”‚       â”‚   â”œâ”€â”€ main_window.py   # Main application window
â”‚       â”‚   â”œâ”€â”€ styles.py        # Material Design themes
â”‚       â”‚   â””â”€â”€ widgets/         # Custom widgets
â”‚       â”‚       â””â”€â”€ eeg_plot.py  # EEG visualization widget
â”‚       â””â”€â”€ utils/               # Utilities
â”‚           â””â”€â”€ logger.py        # Logging configuration
â”œâ”€â”€ tests/                       # Unit and integration tests
â”œâ”€â”€ data/                        # Data directory (not in git)
â”œâ”€â”€ models/                      # Saved models (not in git)
â”œâ”€â”€ logs/                        # Application logs (not in git)
â”œâ”€â”€ pyproject.toml              # Project configuration
â”œâ”€â”€ .pre-commit-config.yaml     # Pre-commit hooks
â”œâ”€â”€ .env.example                # Example environment file
â””â”€â”€ README.md                   # This file
```

## ğŸ§ª Testing

```bash
# Run all tests
hatch run test

# Run with coverage
hatch run test-cov

# Generate HTML coverage report
hatch run cov-report
```

## ğŸ”§ Development

### Code Quality

This project uses modern Python development tools:

- **Black** - Code formatting
- **Ruff** - Fast linting
- **MyPy** - Static type checking
- **Pre-commit** - Git hooks for code quality

```bash
# Format code
hatch run lint:fmt

# Run linters
hatch run lint:style

# Type checking
hatch run lint:typing

# Run all checks
hatch run lint:all
```

### Adding Features

1. Create a new branch: `git checkout -b feature/your-feature`
2. Make your changes following the coding standards
3. Add tests for new functionality
4. Run pre-commit hooks: `pre-commit run --all-files`
5. Commit your changes: `git commit -m "Add your feature"`
6. Push and create a pull request

## ğŸ“ˆ Performance

The modernized version includes several performance improvements:

- âœ… **Fixed timer intervals** - Changed from 1ms to appropriate intervals (100ms for plots, 33ms for camera)
- âœ… **Proper resource cleanup** - Fixed memory leaks in matplotlib canvas
- âœ… **Optimized rendering** - Reduced unnecessary redraws
- âœ… **Efficient data processing** - Vectorized operations with NumPy
- âœ… **Cross-platform camera support** - Works on Windows, Linux, and macOS

## ğŸ› Troubleshooting

### Camera Not Working

- Check camera permissions
- Try different camera indices (0, 1, 2, etc.) in `.env`
- Ensure no other application is using the camera

### DEAP Data Not Loading

- Verify the data path in `.env`
- Check file permissions
- Ensure files are in the correct format (.dat files)

### High CPU Usage

- Increase `PLOT_UPDATE_INTERVAL` and `CAMERA_UPDATE_INTERVAL` in `.env`
- Disable face detection when not needed
- Close unused tabs

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **DEAP Dataset** - [A Database for Emotion Analysis using Physiological Signals](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/)
- **PyQt6** - Cross-platform GUI framework
- **MTCNN** - Face detection model
- **Material Design** - Design system
- **Font Awesome** - Icon library

## ğŸ“§ Contact

**AIATUS** - Advanced AI and Information Technologies

For questions and support, please open an issue on GitHub.

---

<div align="center">

**Made with â¤ï¸ by AIATUS**

â­ Star this repository if you find it helpful!

</div>
